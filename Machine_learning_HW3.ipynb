{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - General Data Preprocessing (20 points)\n",
    "\n",
    "### Libraries that can be used: numpy, scipy, pandas, scikit-learn, cvxpy, imbalanced-learn\n",
    "Any libraries used in the discussion materials are also allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"garments_worker_productivity.csv\")\n",
    "\n",
    "df.drop('date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique values for day:\n",
      "['Thursday' 'Saturday' 'Sunday' 'Monday' 'Tuesday' 'Wednesday']\n",
      "unique values for quarter:\n",
      "['Quarter1' 'Quarter2' 'Quarter3' 'Quarter4' 'Quarter5']\n",
      "unique values for department:\n",
      "['sweing' 'finishing ' 'finishing']\n",
      "unique values for team:\n",
      "[ 8  1 11 12  6  7  2  3  9 10  5  4]\n"
     ]
    }
   ],
   "source": [
    "print(\"unique values for day:\")\n",
    "print(df.day.unique())\n",
    "\n",
    "print(\"unique values for quarter:\")\n",
    "print(df.quarter.unique())\n",
    "\n",
    "print(\"unique values for department:\")\n",
    "print(df.department.unique())\n",
    "\n",
    "print(\"unique values for team:\")\n",
    "print(df.team.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns with empty values\n",
      "quarter               False\n",
      "department            False\n",
      "day                   False\n",
      "team                  False\n",
      "smv                   False\n",
      "wip                    True\n",
      "over_time             False\n",
      "incentive             False\n",
      "idle_time             False\n",
      "idle_men              False\n",
      "no_of_style_change    False\n",
      "no_of_workers         False\n",
      "satisfied             False\n",
      "dtype: bool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/w4qqp9cn2pzf07v9rtxqb53h0000gn/T/ipykernel_22379/1406840763.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.satisfied[i] = 1\n",
      "/var/folders/nw/w4qqp9cn2pzf07v9rtxqb53h0000gn/T/ipykernel_22379/1406840763.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.satisfied[i] = 0\n"
     ]
    }
   ],
   "source": [
    "df['department'] = df['department'].str.replace('sweing', 'sewing')\n",
    "df['department'] = df['department'].str.replace('finishing ', 'finishing')\n",
    "\n",
    "df['satisfied'] = None\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if df.actual_productivity[i] < df.targeted_productivity[i]:\n",
    "        df.satisfied[i] = 0\n",
    "    else:\n",
    "        df.satisfied[i] = 1\n",
    "\n",
    "df.drop('actual_productivity', axis=1, inplace=True)\n",
    "df.drop('targeted_productivity', axis=1, inplace=True)\n",
    "\n",
    "print(\"columns with empty values\")\n",
    "print(df.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(value={'wip': 0})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Naïve Bayes Classifier (40 points in total)\n",
    "\n",
    "### Exercise 2.1 - Additional Data Preprocessing (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "cat_vars = {'day': df[\"day\"],\n",
    "            'quarter': df[\"quarter\"],\n",
    "            'department': df[\"department\"],\n",
    "            'team': df[\"team\"]}\n",
    "cat_varsdf = pd.DataFrame(cat_vars)\n",
    "\n",
    "myData_encoder = LabelEncoder()\n",
    "\n",
    "Day_encoded =  myData_encoder.fit_transform(cat_varsdf.day) \n",
    "Quarter_encoded = myData_encoder.fit_transform(cat_varsdf.quarter)\n",
    "Department_encoded = myData_encoder.fit_transform(cat_varsdf.department)\n",
    "Team_encoded = myData_encoder.fit_transform(cat_varsdf.team)\n",
    "\n",
    "Day_encoded = pd.DataFrame(Day_encoded)\n",
    "Quarter_encoded = pd.DataFrame(Quarter_encoded)\n",
    "Department_encoded = pd.DataFrame(Department_encoded)\n",
    "Team_encoded = pd.DataFrame(Team_encoded)\n",
    "\n",
    "cat_varsdf.day = Day_encoded\n",
    "cat_varsdf.quarter = Quarter_encoded\n",
    "cat_varsdf.department = Department_encoded\n",
    "cat_varsdf.team = Team_encoded\n",
    "# print(Team_encoded)\n",
    "\n",
    "df.satisfied = df.satisfied.apply(int)\n",
    "\n",
    "#Splitting the dataset into training and testing variables\n",
    "X_train, X_test, y_train, y_test = train_test_split(cat_varsdf, df.satisfied, test_size=0.2,random_state=20)\n",
    "#keeping 80% as training data and 20% as testing data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2 - Naïve Bayes Classifier for Categorical Attributes (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.26      0.39        65\n",
      "           1       0.78      0.97      0.87       175\n",
      "\n",
      "    accuracy                           0.78       240\n",
      "   macro avg       0.78      0.62      0.63       240\n",
      "weighted avg       0.78      0.78      0.74       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remember to do this task with your processed data from Exercise 2.1\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "\n",
    "\n",
    "NB = CategoricalNB() # Try CategoricalNB here.\n",
    "NB.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, NB.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.3 - Naïve Bayes Classifier for Numerical Attributes (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "num_vars = {'smv': df[\"smv\"],\n",
    "            'wip': df[\"wip\"],\n",
    "            'over_time': df[\"over_time\"],\n",
    "            'incentive': df[\"incentive\"],\n",
    "            'idle_time': df[\"idle_time\"],\n",
    "            'idle_men': df[\"idle_men\"],\n",
    "            'no_of_style_change': df[\"no_of_style_change\"],\n",
    "            'no_of_workers': df[\"no_of_workers\"],}\n",
    "\n",
    "num_varsdf = pd.DataFrame(num_vars)\n",
    "\n",
    "Scaler = MinMaxScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = num_varsdf['smv'].values.reshape(-1, 1) #returns a numpy array\n",
    "Smv_encoded =  Scaler.fit_transform(x) \n",
    "\n",
    "x = num_varsdf['wip'].values.reshape(-1, 1) #returns a numpy array\n",
    "Wip_encoded = Scaler.fit_transform(x)\n",
    "\n",
    "x = num_varsdf['over_time'].values.reshape(-1, 1) #returns a numpy array\n",
    "Over_time_encoded = Scaler.fit_transform(x)\n",
    "\n",
    "x = num_varsdf['incentive'].values.reshape(-1, 1) #returns a numpy array\n",
    "Incentive_encoded = Scaler.fit_transform(x)\n",
    "\n",
    "x = num_varsdf['idle_time'].values.reshape(-1, 1) #returns a numpy array\n",
    "Idle_time_encoded =  Scaler.fit_transform(x) \n",
    "\n",
    "x = num_varsdf['idle_men'].values.reshape(-1, 1) #returns a numpy array\n",
    "Idle_men_encoded = Scaler.fit_transform(x)\n",
    "\n",
    "x = num_varsdf['no_of_style_change'].values.reshape(-1, 1) #returns a numpy array\n",
    "No_of_style_change_encoded = Scaler.fit_transform(x)\n",
    "\n",
    "x = num_varsdf['no_of_workers'].values.reshape(-1, 1) #returns a numpy array\n",
    "No_of_workers_encoded = Scaler.fit_transform(x)\n",
    "\n",
    "Smv_encoded = pd.DataFrame(Smv_encoded)\n",
    "Wip_encoded = pd.DataFrame(Wip_encoded)\n",
    "Over_time_encoded = pd.DataFrame(Over_time_encoded)\n",
    "Incentive_encoded = pd.DataFrame(Incentive_encoded)\n",
    "Idle_time_encoded = pd.DataFrame(Idle_time_encoded)\n",
    "Idle_men_encoded = pd.DataFrame(Idle_men_encoded)\n",
    "No_of_style_change_encoded = pd.DataFrame(No_of_style_change_encoded)\n",
    "No_of_workers_encoded = pd.DataFrame(No_of_workers_encoded)\n",
    "\n",
    "num_varsdf.smv = Smv_encoded\n",
    "num_varsdf.wip = Wip_encoded\n",
    "num_varsdf.over_time = Over_time_encoded\n",
    "num_varsdf.incentive = Incentive_encoded\n",
    "num_varsdf.idle_time = Idle_time_encoded\n",
    "num_varsdf.idle_men = Idle_men_encoded\n",
    "num_varsdf.no_of_style_change = No_of_style_change_encoded\n",
    "num_varsdf.no_of_workers = No_of_workers_encoded\n",
    "\n",
    "# #Splitting the dataset into training and testing variables\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(num_varsdf, df.satisfied, test_size=0.2,random_state=20)\n",
    " \n",
    "#keeping 80% as training data and 20% as testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.06      0.11        65\n",
      "           1       0.74      0.99      0.85       175\n",
      "\n",
      "    accuracy                           0.74       240\n",
      "   macro avg       0.77      0.53      0.48       240\n",
      "weighted avg       0.76      0.74      0.65       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "NB = GaussianNB()\n",
    "\n",
    "scaler.fit(X_train1)\n",
    "NB.fit(scaler.transform(X_train1), np.asarray(y_train1))\n",
    "\n",
    "print(classification_report(y_test1, NB.predict(scaler.transform(X_test1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercies 3 - SVM Classifier (40 points in total)\n",
    "\n",
    "### Exercise 3.1 - Additional Data Preprocessing (10 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "df.satisfied = df.satisfied.apply(int)\n",
    "Scaler = preprocessing.StandardScaler()\n",
    "\n",
    "df_copy = df.copy().drop(columns = ['quarter', 'department', 'team', 'day'])\n",
    "df_copy = pd.concat([df_copy, pd.get_dummies(df['quarter'].apply(str))], axis=1)\n",
    "df_copy = pd.concat([df_copy, pd.get_dummies(df['department'].apply(str))], axis=1)\n",
    "df_copy = pd.concat([df_copy, pd.get_dummies(df['team'].apply(str))], axis=1)\n",
    "df_copy = pd.concat([df_copy, pd.get_dummies(df['day'].apply(str))], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# #Splitting the dataset into training and testing variables\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_copy.copy().drop(columns = ['satisfied']), df_copy.satisfied, test_size=0.2,random_state=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2 - SVM with Different Kernels (20 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### SVC with linear kernel #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.12      0.21        65\n",
      "           1       0.75      0.98      0.85       175\n",
      "\n",
      "    accuracy                           0.75       240\n",
      "   macro avg       0.71      0.55      0.53       240\n",
      "weighted avg       0.73      0.75      0.68       240\n",
      " \n",
      "\n",
      "##### SVC with RBF kernel #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.20      0.31        65\n",
      "           1       0.76      0.97      0.85       175\n",
      "\n",
      "    accuracy                           0.76       240\n",
      "   macro avg       0.72      0.58      0.58       240\n",
      "weighted avg       0.74      0.76      0.71       240\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "clf = SVC(kernel='linear')\n",
    "clf_li = LinearSVC(dual=False)\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "clf.fit(scaler.transform(X_train), np.asarray(y_train))\n",
    "\n",
    "\n",
    "print('##### SVC with linear kernel #####')\n",
    "print(classification_report(y_test, clf.predict(scaler.transform(X_test))), '\\n')\n",
    "\n",
    "clf = SVC(kernel = 'rbf')\n",
    "          \n",
    "clf.fit(scaler.transform(X_train), np.asarray(y_train))\n",
    "\n",
    "print('##### SVC with RBF kernel #####')\n",
    "print(classification_report(y_test, clf.predict(scaler.transform(X_test))), '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3 - SVM with Over-sampling (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value counts for satisfied:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    700\n",
       "0    257\n",
       "Name: satisfied, dtype: int64"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "\n",
    "print(\"value counts for satisfied:\")\n",
    "y_train.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    700\n",
       "0    700\n",
       "Name: satisfied, dtype: int64"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "X_res, y_res = ros.fit_resample(X_train, y_train)\n",
    "y_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### SVC with linear kernel #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.65      0.55        65\n",
      "           1       0.85      0.74      0.79       175\n",
      "\n",
      "    accuracy                           0.71       240\n",
      "   macro avg       0.66      0.69      0.67       240\n",
      "weighted avg       0.75      0.71      0.72       240\n",
      " \n",
      "\n",
      "##### SVC with RBF kernel #####\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.60      0.57        65\n",
      "           1       0.85      0.81      0.83       175\n",
      "\n",
      "    accuracy                           0.75       240\n",
      "   macro avg       0.69      0.71      0.70       240\n",
      "weighted avg       0.76      0.75      0.76       240\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "clf = SVC(kernel='linear')\n",
    "clf_li = LinearSVC(dual=False)\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "clf.fit(scaler.transform(X_res), np.asarray(y_res))\n",
    "\n",
    "\n",
    "print('##### SVC with linear kernel #####')\n",
    "print(classification_report(y_test, clf.predict(scaler.transform(X_test))), '\\n')\n",
    "\n",
    "clf = SVC(kernel = 'rbf')\n",
    "          \n",
    "clf.fit(scaler.transform(X_res), np.asarray(y_res))\n",
    "\n",
    "print('##### SVC with RBF kernel #####')\n",
    "print(classification_report(y_test, clf.predict(scaler.transform(X_test))), '\\n')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8511e03213d67b3102df803bbfd9f3594c87d6a47de97c6aef092a22eb5d53b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
